{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Inference\n",
    "\n",
    "The model that has been trained will be tested on data that is not included in the train-set or test-set. This data must be in the original format, not data that has been scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Import Modul\n",
    "\n",
    "We will import the required modules first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Load Model\n",
    "\n",
    "We will load the list of columns that will be used by the model, scaler, PCA, and KMeans model into the inference file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "# Membaca list kolom numerik dari file JSON\n",
    "with open('list_used_col.txt', 'r') as file_1:\n",
    "  list_used_col = json.load(file_1)\n",
    "\n",
    "# Memuat model encoder dari file pickle\n",
    "with open('model_scaler.pkl', 'rb') as file_2:\n",
    "  model_scaler = pickle.load(file_2)\n",
    "\n",
    "# Memuat model scaler dari file pickle\n",
    "with open('model_pca.pkl', 'rb') as file_3:\n",
    "  model_pca = pickle.load(file_3)\n",
    "\n",
    "# Memuat model Linear Regression dari file pickle\n",
    "with open('model_kmeans.pkl', 'rb') as file_4:\n",
    "  model_kmeans = pickle.load(file_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>BALANCE</th>\n",
       "      <th>BALANCE_FREQUENCY</th>\n",
       "      <th>PURCHASES</th>\n",
       "      <th>ONEOFF_PURCHASES</th>\n",
       "      <th>INSTALLMENTS_PURCHASES</th>\n",
       "      <th>CASH_ADVANCE</th>\n",
       "      <th>PURCHASES_FREQUENCY</th>\n",
       "      <th>ONEOFF_PURCHASES_FREQUENCY</th>\n",
       "      <th>PURCHASES_INSTALLMENTS_FREQUENCY</th>\n",
       "      <th>CASH_ADVANCE_FREQUENCY</th>\n",
       "      <th>CASH_ADVANCE_TRX</th>\n",
       "      <th>PURCHASES_TRX</th>\n",
       "      <th>CREDIT_LIMIT</th>\n",
       "      <th>PAYMENTS</th>\n",
       "      <th>MINIMUM_PAYMENTS</th>\n",
       "      <th>PRC_FULL_PAYMENT</th>\n",
       "      <th>TENURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3242</td>\n",
       "      <td>20023</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1034</td>\n",
       "      <td>5034</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>50300</td>\n",
       "      <td>10000</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CUST_ID  BALANCE  BALANCE_FREQUENCY  PURCHASES  ONEOFF_PURCHASES  \\\n",
       "0     3242    20023                0.5       1034              5034   \n",
       "\n",
       "   INSTALLMENTS_PURCHASES  CASH_ADVANCE  PURCHASES_FREQUENCY  \\\n",
       "0                       0          5000                  0.6   \n",
       "\n",
       "   ONEOFF_PURCHASES_FREQUENCY  PURCHASES_INSTALLMENTS_FREQUENCY  \\\n",
       "0                        0.05                                 0   \n",
       "\n",
       "   CASH_ADVANCE_FREQUENCY  CASH_ADVANCE_TRX  PURCHASES_TRX  CREDIT_LIMIT  \\\n",
       "0                    0.05                15             20         50300   \n",
       "\n",
       "   PAYMENTS  MINIMUM_PAYMENTS  PRC_FULL_PAYMENT  TENURE  \n",
       "0     10000             15000               0.1      12  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_inf = {\n",
    "    \"CUST_ID\": [3242],\n",
    "    \"BALANCE\": [20023],  \n",
    "    \"BALANCE_FREQUENCY\": [0.5], \n",
    "    \"PURCHASES\": [1034],  \n",
    "    \"ONEOFF_PURCHASES\": [5034],\n",
    "    \"INSTALLMENTS_PURCHASES\": [0],\n",
    "    \"CASH_ADVANCE\": [5000],  \n",
    "    \"PURCHASES_FREQUENCY\": [0.60],\n",
    "    \"ONEOFF_PURCHASES_FREQUENCY\": [0.05],\n",
    "    \"PURCHASES_INSTALLMENTS_FREQUENCY\": [0],\n",
    "    \"CASH_ADVANCE_FREQUENCY\": [0.05],  \n",
    "    \"CASH_ADVANCE_TRX\": [15],  \n",
    "    \"PURCHASES_TRX\": [20],  \n",
    "    \"CREDIT_LIMIT\": [50300],\n",
    "    \"PAYMENTS\": [10000], \n",
    "    \"MINIMUM_PAYMENTS\": [15000], \n",
    "    \"PRC_FULL_PAYMENT\": [0.1],  \n",
    "    \"TENURE\": [12]  \n",
    "}\n",
    "data_inf = pd.DataFrame(data_inf)\n",
    "data_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we type all the data whose columns are the same as the original data, then we will select certain columns that are only used by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inf_final = data_inf[list_used_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then from the selection column, we do scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ogi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\Ogi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\Ogi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "# Numerical data scaling of new data using a scaler model\n",
    "data_inf_scaled = model_scaler.transform(data_inf_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scaling, we will do PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ogi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_inf_scaled_pca = model_pca.transform(data_inf_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.4 Predict Inference\n",
    "\n",
    "After going through scaling and PCA, we next run our classification prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict using Linear Regression Models\n",
    "# Predict targets for new data using Linear Regression models\n",
    "data_inf_pred = model_kmeans.predict(data_inf_scaled_pca)\n",
    "\n",
    "# Displays predictions for new data\n",
    "data_inf_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the model can perform clustering according to expectations.\n",
    "\n",
    "From the dummy data that we impute, we find that our data is category 2 customers by the K-Means model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
